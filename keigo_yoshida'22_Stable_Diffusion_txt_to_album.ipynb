{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keigoyoshida7/Stable-diffusion/blob/main/keigo_yoshida'22_Stable_Diffusion_txt_to_album.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEBY7IreCvix"
      },
      "source": [
        "# Keigo Yoshida '22 Stable Diffusion txt to album\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgC6MlbjYQhS"
      },
      "source": [
        "# Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGV8CywrSeEu"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWBSOo9pYp01"
      },
      "source": [
        "# Setup Environment for disc jacket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHrnKY7AGnDt"
      },
      "outputs": [],
      "source": [
        "# @title install library\n",
        "dependencies = [\n",
        "  \"albumentations==0.4.3\",\n",
        "  \"diffusers==0.7.1\",\n",
        "  \"opencv-python==4.1.2.30\",\n",
        "  \"pudb==2019.2\",\n",
        "  \"imageio==2.9.0\",\n",
        "  \"imageio-ffmpeg==0.4.2\",\n",
        "  \"pytorch-lightning==1.6.5\",\n",
        "  \"omegaconf==2.1.1\",\n",
        "  \"test-tube>=0.7.5\",\n",
        "  \"streamlit>=0.73.1\",\n",
        "  \"einops==0.3.0\",\n",
        "  \"torch-fidelity==0.3.0\",\n",
        "  \"transformers==4.19.2\",\n",
        "  \"kornia==0.6.8\",\n",
        "]\n",
        "dep_list = \" \".join(map(lambda dep: f\"\\\"{dep}\\\"\",dependencies))\n",
        "print(f\"installing {dep_list}\")\n",
        "!pip install {dep_list}\n",
        "!pip install -e \"git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\"\n",
        "!pip install -e \"git+https://github.com/openai/CLIP.git@main#egg=clip\"\n",
        "!pip install \"invisible-watermark==0.1.5\"\n",
        "\n",
        "print(\"finish!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzYPDfQ7v6FR"
      },
      "outputs": [],
      "source": [
        "!pip install -e taming-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGVkOKAOs6Zk"
      },
      "source": [
        "## ランタイムの再起動\n",
        "\n",
        "メニュー > ランタイム > ランタイムを再起動"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_RkJA5OHj7a"
      },
      "outputs": [],
      "source": [
        "# @title install stable-diffusion\n",
        "%cd /content/\n",
        "!git clone https://github.com/CompVis/stable-diffusion.git\n",
        "%cd /content/stable-diffusion\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U63k5_L1CXGF"
      },
      "outputs": [],
      "source": [
        "# @title download model\n",
        "# https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
        "%cd /content\n",
        "!gdown \"https://drive.google.com/uc?export=download&id=12Hzk3DEzGCmI2ha4XrSCLypz7ia9mn9w\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFBDFxqdZNOw"
      },
      "source": [
        "# execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RyfirfJsciy"
      },
      "outputs": [],
      "source": [
        "# @title import module\n",
        "\n",
        "%cd /content/stable-diffusion\n",
        "\n",
        "import argparse, os, sys, glob\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from tqdm import tqdm, trange\n",
        "from imwatermark import WatermarkEncoder\n",
        "from itertools import islice\n",
        "from einops import rearrange\n",
        "from torchvision.utils import make_grid\n",
        "import time\n",
        "from pytorch_lightning import seed_everything\n",
        "from torch import autocast\n",
        "from contextlib import contextmanager, nullcontext\n",
        "\n",
        "from ldm.util import instantiate_from_config\n",
        "from ldm.models.diffusion.ddim import DDIMSampler\n",
        "from ldm.models.diffusion.plms import PLMSSampler\n",
        "\n",
        "from diffusers.pipelines.stable_diffusion.safety_checker import StableDiffusionSafetyChecker\n",
        "from transformers import AutoFeatureExtractor\n",
        "\n",
        "from IPython.display import Image as IPImage, display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUgi8lnhuJye"
      },
      "outputs": [],
      "source": [
        "# @title define functions etc\n",
        "\n",
        "safety_model_id = \"CompVis/stable-diffusion-safety-checker\"\n",
        "safety_feature_extractor = AutoFeatureExtractor.from_pretrained(safety_model_id)\n",
        "safety_checker = StableDiffusionSafetyChecker.from_pretrained(safety_model_id)\n",
        "\n",
        "def chunk(it, size):\n",
        "    it = iter(it)\n",
        "    return iter(lambda: tuple(islice(it, size)), ())\n",
        "\n",
        "\n",
        "def numpy_to_pil(images):\n",
        "    \"\"\"\n",
        "    Convert a numpy image or a batch of images to a PIL image.\n",
        "    \"\"\"\n",
        "    if images.ndim == 3:\n",
        "        images = images[None, ...]\n",
        "    images = (images * 255).round().astype(\"uint8\")\n",
        "    pil_images = [Image.fromarray(image) for image in images]\n",
        "\n",
        "    return pil_images\n",
        "\n",
        "\n",
        "def load_model_from_config(config, ckpt, verbose=False):\n",
        "    print(f\"Loading model from {ckpt}\")\n",
        "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
        "    if \"global_step\" in pl_sd:\n",
        "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
        "    sd = pl_sd[\"state_dict\"]\n",
        "    model = instantiate_from_config(config.model)\n",
        "    m, u = model.load_state_dict(sd, strict=False)\n",
        "    if len(m) > 0 and verbose:\n",
        "        print(\"missing keys:\")\n",
        "        print(m)\n",
        "    if len(u) > 0 and verbose:\n",
        "        print(\"unexpected keys:\")\n",
        "        print(u)\n",
        "\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def put_watermark(img, wm_encoder=None):\n",
        "    if wm_encoder is not None:\n",
        "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "        img = wm_encoder.encode(img, 'dwtDct')\n",
        "        img = Image.fromarray(img[:, :, ::-1])\n",
        "    return img\n",
        "\n",
        "\n",
        "def load_replacement(x):\n",
        "    try:\n",
        "        hwc = x.shape\n",
        "        y = Image.open(\"assets/rick.jpeg\").convert(\"RGB\").resize((hwc[1], hwc[0]))\n",
        "        y = (np.array(y)/255.0).astype(x.dtype)\n",
        "        assert y.shape == x.shape\n",
        "        return y\n",
        "    except Exception:\n",
        "        return x\n",
        "\n",
        "\n",
        "def check_safety(x_image):\n",
        "    safety_checker_input = safety_feature_extractor(numpy_to_pil(x_image), return_tensors=\"pt\")\n",
        "    x_checked_image, has_nsfw_concept = safety_checker(images=x_image, clip_input=safety_checker_input.pixel_values)\n",
        "    assert x_checked_image.shape[0] == len(has_nsfw_concept)\n",
        "    for i in range(len(has_nsfw_concept)):\n",
        "        if has_nsfw_concept[i]:\n",
        "            x_checked_image[i] = load_replacement(x_checked_image[i])\n",
        "    return x_checked_image, has_nsfw_concept\n",
        "\n",
        "config = OmegaConf.load(\"/content/stable-diffusion/configs/stable-diffusion/v1-inference.yaml\")\n",
        "model = load_model_from_config(config, \"/content/sd-v1-4.ckpt\")\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i4peynKS5ZX"
      },
      "outputs": [],
      "source": [
        "#@title **Setup Environment for music**\n",
        "\n",
        "import subprocess, time\n",
        "print(\"Setting up environment...\")\n",
        "start_time = time.time()\n",
        "all_process = [\n",
        "    ['pip', 'install', 'torch==1.12.1+cu113', 'torchvision==0.13.1+cu113', '--extra-index-url', 'https://download.pytorch.org/whl/cu113'],\n",
        "    ['pip', 'install', '-U', 'sentence-transformers'],\n",
        "    ['pip', 'install', 'httpx'],\n",
        "]\n",
        "for process in all_process:\n",
        "    running = subprocess.run(process,stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "end_time = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtPEaNgjTAA0"
      },
      "outputs": [],
      "source": [
        "#@title **Define Mubert methods and pre-compute things**\n",
        "\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "minilm = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "mubert_tags_string = 'tribal,action,kids,neo-classic,run 130,pumped,jazz / funk,ethnic,dubtechno,reggae,acid jazz,liquidfunk,funk,witch house,tech house,underground,artists,mystical,disco,sensorium,r&b,agender,psychedelic trance / psytrance,peaceful,run 140,piano,run 160,setting,meditation,christmas,ambient,horror,cinematic,electro house,idm,bass,minimal,underscore,drums,glitchy,beautiful,technology,tribal house,country pop,jazz & funk,documentary,space,classical,valentines,chillstep,experimental,trap,new jack swing,drama,post-rock,tense,corporate,neutral,happy,analog,funky,spiritual,sberzvuk special,chill hop,dramatic,catchy,holidays,fitness 90,optimistic,orchestra,acid techno,energizing,romantic,minimal house,breaks,hyper pop,warm up,dreamy,dark,urban,microfunk,dub,nu disco,vogue,keys,hardcore,aggressive,indie,electro funk,beauty,relaxing,trance,pop,hiphop,soft,acoustic,chillrave / ethno-house,deep techno,angry,dance,fun,dubstep,tropical,latin pop,heroic,world music,inspirational,uplifting,atmosphere,art,epic,advertising,chillout,scary,spooky,slow ballad,saxophone,summer,erotic,jazzy,energy 100,kara mar,xmas,atmospheric,indie pop,hip-hop,yoga,reggaeton,lounge,travel,running,folk,chillrave & ethno-house,detective,darkambient,chill,fantasy,minimal techno,special,night,tropical house,downtempo,lullaby,meditative,upbeat,glitch hop,fitness,neurofunk,sexual,indie rock,future pop,jazz,cyberpunk,melancholic,happy hardcore,family / kids,synths,electric guitar,comedy,psychedelic trance & psytrance,edm,psychedelic rock,calm,zen,bells,podcast,melodic house,ethnic percussion,nature,heavy,bassline,indie dance,techno,drumnbass,synth pop,vaporwave,sad,8-bit,chillgressive,deep,orchestral,futuristic,hardtechno,nostalgic,big room,sci-fi,tutorial,joyful,pads,minimal 170,drill,ethnic 108,amusing,sleepy ambient,psychill,italo disco,lofi,house,acoustic guitar,bassline house,rock,k-pop,synthwave,deep house,electronica,gabber,nightlife,sport & fitness,road trip,celebration,electro,disco house,electronic'\n",
        "mubert_tags = np.array(mubert_tags_string.split(','))\n",
        "mubert_tags_embeddings = minilm.encode(mubert_tags)\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "import httpx\n",
        "import json\n",
        "\n",
        "def get_track_by_tags(tags, pat, duration, maxit=20, autoplay=False, loop=False):\n",
        "  if loop:\n",
        "    mode = \"loop\"\n",
        "  else:\n",
        "    mode = \"track\"\n",
        "  r = httpx.post('https://api-b2b.mubert.com/v2/RecordTrackTTM', \n",
        "      json={\n",
        "          \"method\":\"RecordTrackTTM\",\n",
        "          \"params\": {\n",
        "              \"pat\": pat, \n",
        "              \"duration\": duration,\n",
        "              \"tags\": tags,\n",
        "              \"mode\": mode\n",
        "          }\n",
        "      })\n",
        "\n",
        "  rdata = json.loads(r.text)\n",
        "  assert rdata['status'] == 1, rdata['error']['text']\n",
        "  trackurl = rdata['data']['tasks'][0]['download_link']\n",
        "\n",
        "  print('Generating track ', end='')\n",
        "  for i in range(maxit):\n",
        "      r = httpx.get(trackurl)\n",
        "      if r.status_code == 200:\n",
        "          display(Audio(trackurl, autoplay=autoplay))\n",
        "          break\n",
        "      time.sleep(1)\n",
        "      print('.', end='')\n",
        "\n",
        "def find_similar(em, embeddings, method='cosine'):\n",
        "    scores = []\n",
        "    for ref in embeddings:\n",
        "        if method == 'cosine': \n",
        "            scores.append(1 - np.dot(ref, em)/(np.linalg.norm(ref)*np.linalg.norm(em)))\n",
        "        if method == 'norm': \n",
        "            scores.append(np.linalg.norm(ref - em))\n",
        "    return np.array(scores), np.argsort(scores)\n",
        "\n",
        "def get_tags_for_prompts(prompts, top_n=3, debug=False):\n",
        "    prompts_embeddings = minilm.encode(prompts)\n",
        "    ret = []\n",
        "    for i, pe in enumerate(prompts_embeddings):\n",
        "        scores, idxs = find_similar(pe, mubert_tags_embeddings)\n",
        "        top_tags = mubert_tags[idxs[:top_n]]\n",
        "        top_prob = 1 - scores[idxs[:top_n]]\n",
        "        if debug:\n",
        "            print(f\"Prompt: {prompts[i]}\\nTags: {', '.join(top_tags)}\\nScores: {top_prob}\\n\\n\\n\")\n",
        "        ret.append((prompts[i], list(top_tags)))\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iDSSX51TIPp"
      },
      "outputs": [],
      "source": [
        "#@markdown **Get personal access token in Mubert and define API methods**\n",
        "email = \"sample@gmail.com\" #@param {type:\"string\"}\n",
        "\n",
        "r = httpx.post('https://api-b2b.mubert.com/v2/GetServiceAccess', \n",
        "    json={\n",
        "        \"method\":\"GetServiceAccess\",\n",
        "        \"params\": {\n",
        "            \"email\": email,\n",
        "            \"license\":\"ttmmubertlicense#f0acYBenRcfeFpNT4wpYGaTQIyDI4mJGv5MfIhBFz97NXDwDNFHmMRsBSzmGsJwbTpP1A6i07AXcIeAHo5\",\n",
        "            \"token\":\"4951f6428e83172a4f39de05d5b3ab10d58560b8\",\n",
        "            \"mode\": \"loop\"\n",
        "        }\n",
        "    })\n",
        "\n",
        "rdata = json.loads(r.text)\n",
        "assert rdata['status'] == 1, \"probably incorrect e-mail\"\n",
        "pat = rdata['data']['pat']\n",
        "print(f'Got token: {pat}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fw5pr07uvN0J"
      },
      "outputs": [],
      "source": [
        "# @title parameter settings { run: \"auto\" }\n",
        "\n",
        "# @markdown ### basic\n",
        "\n",
        "prompt = \"wings of freedom\" # @param { type: \"string\" }\n",
        "duration = 90 #@param {type:\"number\"}\n",
        "loop = False #@param {type:\"boolean\"}\n",
        "\n",
        "def generate_track_by_prompt(prompt, duration, loop=False):\n",
        "  _, tags = get_tags_for_prompts([prompt,])[0]\n",
        "  try:\n",
        "    get_track_by_tags(tags, pat, duration, autoplay=True, loop=loop)\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "  print('\\n')\n",
        "\n",
        "outdir = '/content/results' # @param { type: \"string\" }\n",
        "width = 512 # @param { type: \"integer\" }\n",
        "height = 512 # @param { type: \"integer\" }\n",
        "n_samples = 1 # @param { type: \"integer\", min: 1 }\n",
        "seed = 43 # @param { type: \"integer\" }\n",
        "scale = 7.5 # @param { type: \"number\", min: 0.0 }\n",
        "\n",
        "# @markdown ----\n",
        "# @markdown ### advanced\n",
        "\n",
        "n_iter = 1 # @param { type: \"integer\" }\n",
        "skip_grid = False # @param { type: \"boolean\" }\n",
        "skip_save = False # @param { type: \"boolean\" }\n",
        "ddim_steps = 50 # @param { type: \"integer\" }\n",
        "plms = False # @param { type: \"boolean\" }\n",
        "fixed_code = False # @param { type: \"boolean\" }\n",
        "ddim_eta = 0.0 # @param { type: \"number\" }\n",
        "latent_channels = 4 # @param { type: \"integer\", min: 1 }\n",
        "downsampling_factor = 8 # @param { type: \"integer\", min: 1 }\n",
        "n_rows = 0 # @param { type: \"integer\", min: 0 }\n",
        "precision = \"autocast\" # @param [ \"full\", \"autocast\" ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNeI4xtszcYG"
      },
      "outputs": [],
      "source": [
        "# @title drop the album\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "seed_everything(seed)\n",
        "\n",
        "if plms:\n",
        "    sampler = PLMSSampler(model)\n",
        "else:\n",
        "    sampler = DDIMSampler(model)\n",
        "\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "outpath = outdir\n",
        "\n",
        "wm = \"DDA 2022\"\n",
        "wm_encoder = WatermarkEncoder()\n",
        "wm_encoder.set_watermark('bytes', wm.encode('utf-8'))\n",
        "\n",
        "batch_size = n_samples\n",
        "n_rows = n_rows if n_rows > 0 else batch_size\n",
        "assert prompt is not None\n",
        "data = [ batch_size * [prompt] ]\n",
        "\n",
        "sample_path = os.path.join(outpath, \"samples\")\n",
        "os.makedirs(sample_path, exist_ok=True)\n",
        "base_count = len(os.listdir(sample_path))\n",
        "grid_count = len(os.listdir(outpath)) - 1\n",
        "\n",
        "start_code = None\n",
        "if fixed_code:\n",
        "    start_code = torch.randn([ n_samples, latent_channels, height // downsampling_factor, width // downsampling_factor ], device=device)\n",
        "\n",
        "precision_scope = autocast if precision==\"autocast\" else nullcontext\n",
        "with torch.no_grad():\n",
        "    with precision_scope(\"cuda\"):\n",
        "        with model.ema_scope():\n",
        "            tic = time.time()\n",
        "            all_samples = list()\n",
        "            for n in trange(n_iter, desc=\"Sampling\"):\n",
        "                for prompts in tqdm(data, desc=\"data\"):\n",
        "                    uc = None\n",
        "                    if scale != 1.0:\n",
        "                        uc = model.get_learned_conditioning(batch_size * [\"\"])\n",
        "                    if isinstance(prompts, tuple):\n",
        "                        prompts = list(prompts)\n",
        "                    c = model.get_learned_conditioning(prompts)\n",
        "                    shape = [ latent_channels, height // downsampling_factor, width // downsampling_factor ]\n",
        "                    samples_ddim, _ = sampler.sample(S = ddim_steps,\n",
        "                                                      conditioning = c,\n",
        "                                                      batch_size = n_samples,\n",
        "                                                      shape = shape,\n",
        "                                                      verbose = False,\n",
        "                                                      unconditional_guidance_scale = scale,\n",
        "                                                      unconditional_conditioning = uc,\n",
        "                                                      eta = ddim_eta,\n",
        "                                                      x_T = start_code)\n",
        "\n",
        "                    x_samples_ddim = model.decode_first_stage(samples_ddim)\n",
        "                    x_samples_ddim = torch.clamp((x_samples_ddim + 1.0) / 2.0, min=0.0, max=1.0)\n",
        "                    x_samples_ddim = x_samples_ddim.cpu().permute(0, 2, 3, 1).numpy()\n",
        "\n",
        "                    x_checked_image, has_nsfw_concept = check_safety(x_samples_ddim)\n",
        "\n",
        "                    x_checked_image_torch = torch.from_numpy(x_checked_image).permute(0, 3, 1, 2)\n",
        "\n",
        "                    if not skip_save:\n",
        "                        for x_sample in x_checked_image_torch:\n",
        "                            x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
        "                            img = Image.fromarray(x_sample.astype(np.uint8))\n",
        "                            img = put_watermark(img, wm_encoder)\n",
        "                            img.save(os.path.join(sample_path, f\"{base_count:05}.png\"))\n",
        "                            base_count += 1\n",
        "\n",
        "                    if not skip_grid:\n",
        "                        all_samples.append(x_checked_image_torch)\n",
        "\n",
        "            if not skip_grid:\n",
        "                # additionally, save as grid\n",
        "                grid = torch.stack(all_samples, 0)\n",
        "                grid = rearrange(grid, 'n b c h w -> (n b) c h w')\n",
        "                grid = make_grid(grid, nrow=n_rows)\n",
        "\n",
        "                # to image\n",
        "                grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n",
        "                img = Image.fromarray(grid.astype(np.uint8))\n",
        "                img = put_watermark(img, wm_encoder)\n",
        "                save_path = os.path.join(outpath, f'grid-{grid_count:04}.png')\n",
        "                img.save(save_path)\n",
        "                display(IPImage(save_path))\n",
        "                grid_count += 1\n",
        "\n",
        "            toc = time.time()\n",
        "\n",
        "generate_track_by_prompt(prompt, duration, loop)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okdnen4MbYbM"
      },
      "source": [
        "# Set up environment for music video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8KQifbuKd7S"
      },
      "source": [
        "# Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54EhnBIIKRks"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "!pip install stable_diffusion_videos[realesrgan]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdzzD7EPKm_g"
      },
      "source": [
        "# Hugging face access token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCL-6wzDKdR5"
      },
      "outputs": [],
      "source": [
        "access_tokens=\"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\" # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGi69xWTK2At"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aahHaCYKt_r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from stable_diffusion_videos import StableDiffusionWalkPipeline, Interface\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXCP6j_KK8jd"
      },
      "source": [
        "# Loading model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcEEQHaGK49P"
      },
      "outputs": [],
      "source": [
        "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "pipeline = StableDiffusionWalkPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    revision=\"fp16\",\n",
        "    use_auth_token=access_tokens\n",
        ").to(\"cuda\")\n",
        "\n",
        "interface = Interface(pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-b46MHILFo-"
      },
      "source": [
        "# Define utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOqODrFuLEaE"
      },
      "outputs": [],
      "source": [
        "def visualize_video_colab(video_path):\n",
        "  \"\"\"動画をインライン表示\"\"\"\n",
        "  mp4 = open(video_path,'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  return HTML(\"\"\"\n",
        "    <video width=400 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "  \"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWmCcq1ULJ9y"
      },
      "source": [
        "# Drop music video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08McDuzaLP2F"
      },
      "outputs": [],
      "source": [
        "interface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ffRtmhRLb-Z"
      },
      "source": [
        "# Music video settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgqQjH1HLZqO"
      },
      "outputs": [],
      "source": [
        "# @markdown src prompt\n",
        "prompt1 = \"take my breath\" # @param {type:\"string\"}\n",
        "# @markdown dst prompt\n",
        "prompt2 = \"just the way god made you\" # @param {type:\"string\"}\n",
        "\n",
        "# @markdown seeds\n",
        "seed1 = 12 #@param {type:\"integer\"}\n",
        "seed2 = 1212 #@param {type:\"integer\"}\n",
        "\n",
        "# @markdown FPS\n",
        "fps = 10 #@param {type:\"integer\"}\n",
        "\n",
        "# @markdown number of interpolation steps\n",
        "num_interpolation_steps = 10 #@param {type:\"integer\"}\n",
        "\n",
        "# @markdown video size\n",
        "height = 512 #@param　{type:\"integer\"}\n",
        "width = 512 #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUdywN3ALmFA"
      },
      "source": [
        "# Music video inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBITuaSXLpI2"
      },
      "outputs": [],
      "source": [
        "video_path = pipeline.walk(\n",
        "    [prompt1, prompt2],\n",
        "    [seed1, seed2],\n",
        "    fps=fps,                      \n",
        "    num_interpolation_steps=num_interpolation_steps,\n",
        "    height=int(height),                \n",
        "    width=int(width),                  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Nisj2BZLtOD"
      },
      "outputs": [],
      "source": [
        "visualize_video_colab(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhpcrEsO2tAb"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/results.zip /content/results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mEBY7IreCvix"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}